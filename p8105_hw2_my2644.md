P8105\_hw2\_my2644
================
ymysherry
9/29/2020

This is my solution to HW2.

``` r
library(tidyverse)
```

    ## ── Attaching packages ────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ───────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

\#\#Problem 1 \#Read the Mr. Trashwheel dataset.

``` r
trashwheel_df =
  read_xlsx(
  "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
  sheet = "Mr. Trash Wheel",
  range = cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read precipitation data for 2018 and 2017

``` r
precip_2018 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
  sheet = "2018 Precipitation",
  skip = 1, 
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2018)  %>%
  relocate(year)
```

``` r
precip_2017 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
  sheet = "2017 Precipitation",
  skip = 1, 
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2017)  %>%
  relocate(year)
```

Now combine annual precipitation.

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )


precip_df = 
bind_rows(precip_2018, precip_2017) 
left_join(precip_df, month_df, by = "month")
```

    ## # A tibble: 24 x 4
    ##     year month total month_name
    ##    <dbl> <dbl> <dbl> <chr>     
    ##  1  2018     1  0.94 January   
    ##  2  2018     2  4.8  February  
    ##  3  2018     3  2.69 March     
    ##  4  2018     4  4.69 April     
    ##  5  2018     5  9.27 May       
    ##  6  2018     6  4.77 June      
    ##  7  2018     7 10.2  July      
    ##  8  2018     8  6.45 August    
    ##  9  2018     9 10.5  September 
    ## 10  2018    10  2.12 October   
    ## # … with 14 more rows

``` r
 nrow(trashwheel_df)
```

    ## [1] 344

This dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trash collects that trash, and stores it in a dumpster. The dataset
contains information on year, months, and trash collected, including
some specific kinds of trash. There are a total of 344 rows in our final
dataset. Additional data sheets include month precipitation data.

Look for total precipitation in 2018 and median number of sports balls
in a dumpster in 2017

``` r
sum(pull(precip_2018,total),na.rm=TRUE)
```

    ## [1] 70.33

The total precipiration in 2018 is 70.33 inches.

``` r
sports_balls_2017_df= filter(trashwheel_df, year==2017)
median(pull(sports_balls_2017_df, sports_balls), na.rm= TRUE)
```

    ## [1] 8

The median number of sports balls in a dumpster in 2017 is 8.

\#\#Problem 2 \#Read and clean the NYC subway dataset. Retain useful
variables and convert the entry variable from character (YES vs NO) to a
logical variable

``` r
nycsubway_df =
  read_csv(
  "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv")
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

``` r
nycsubway_df = janitor::clean_names(nycsubway_df) 

nycsubway_df = 
  select(nycsubway_df, line, station_name, station_latitude, station_longitude, route1:route11, entrance_type, entry, vending, ada)

nycsubway_df =  
  mutate(nycsubway_df, entry = recode (entry, "YES"="TRUE","NO"="FALSE"), entry = as.logical(entry))
skimr::skim(nycsubway_df)
```

|                                                  |               |
| :----------------------------------------------- | :------------ |
| Name                                             | nycsubway\_df |
| Number of rows                                   | 1868          |
| Number of columns                                | 19            |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_   |               |
| Column type frequency:                           |               |
| character                                        | 11            |
| logical                                          | 2             |
| numeric                                          | 6             |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ |               |
| Group variables                                  | None          |

Data summary

**Variable type: character**

| skim\_variable | n\_missing | complete\_rate | min | max | empty | n\_unique | whitespace |
| :------------- | ---------: | -------------: | --: | --: | ----: | --------: | ---------: |
| line           |          0 |           1.00 |   5 |  17 |     0 |        36 |          0 |
| station\_name  |          0 |           1.00 |   4 |  39 |     0 |       356 |          0 |
| route1         |          0 |           1.00 |   1 |   2 |     0 |        24 |          0 |
| route2         |        848 |           0.55 |   1 |   2 |     0 |        20 |          0 |
| route3         |       1374 |           0.26 |   1 |   2 |     0 |        18 |          0 |
| route4         |       1547 |           0.17 |   1 |   1 |     0 |        13 |          0 |
| route5         |       1630 |           0.13 |   1 |   1 |     0 |        12 |          0 |
| route6         |       1741 |           0.07 |   1 |   1 |     0 |         7 |          0 |
| route7         |       1788 |           0.04 |   1 |   2 |     0 |         7 |          0 |
| entrance\_type |          0 |           1.00 |   4 |   9 |     0 |         7 |          0 |
| vending        |          0 |           1.00 |   2 |   3 |     0 |         2 |          0 |

**Variable type: logical**

| skim\_variable | n\_missing | complete\_rate | mean | count               |
| :------------- | ---------: | -------------: | ---: | :------------------ |
| entry          |          0 |              1 | 0.94 | TRU: 1753, FAL: 115 |
| ada            |          0 |              1 | 0.25 | FAL: 1400, TRU: 468 |

**Variable type: numeric**

| skim\_variable     | n\_missing | complete\_rate |    mean |   sd |      p0 |     p25 |     p50 |     p75 |    p100 | hist  |
| :----------------- | ---------: | -------------: | ------: | ---: | ------: | ------: | ------: | ------: | ------: | :---- |
| station\_latitude  |          0 |           1.00 |   40.73 | 0.07 |   40.58 |   40.69 |   40.73 |   40.77 |   40.90 | ▂▅▇▃▂ |
| station\_longitude |          0 |           1.00 | \-73.94 | 0.06 | \-74.03 | \-73.99 | \-73.96 | \-73.91 | \-73.76 | ▇▆▃▂▁ |
| route8             |       1820 |           0.03 |    2.98 | 1.94 |    1.00 |    1.00 |    4.00 |    5.00 |    5.00 | ▇▁▁▂▇ |
| route9             |       1840 |           0.01 |    2.54 | 1.17 |    2.00 |    2.00 |    2.00 |    2.00 |    5.00 | ▇▁▁▁▂ |
| route10            |       1845 |           0.01 |    3.00 | 0.00 |    3.00 |    3.00 |    3.00 |    3.00 |    3.00 | ▁▁▇▁▁ |
| route11            |       1845 |           0.01 |    7.00 | 0.00 |    7.00 |    7.00 |    7.00 |    7.00 |    7.00 | ▁▁▇▁▁ |

\#Describe the dataset

This dataset contains information from the NYC subway transit data. The
dataset contains 19 variables in total, including information on
entrance, exit, station names, routes, lines, as well as specific
longitude and latitude of subway stations. There are a total of 1868
rows in our final dataset. Additional data cleaning has been performed
by the janitor step. Entry variable has been converted from character to
logical by using mutate. This is a tidy dataset with dimensions of
35492. Number of columns represents variables and number of rows
represents observations.

\#\#Answering questions using the NYC subway transit data \#how many
distinct stations (by name and line) are there

``` r
distinct_stations_df = 
  distinct(nycsubway_df, line, station_name, .keep_all = TRUE)
```

1.  There are 465 distinct stations

\#how many stations are ADA compliant

``` r
ADAcompliant_df=
  filter(distinct_stations_df, ada == TRUE)
```

2.  84 stations are ADA compliant

\#What proportion of station entrances / exits without vending allow
entrance

``` r
entrance_novending_df = 
  filter(nycsubway_df, vending == "NO", entry == TRUE) 

novending_df = 
  filter(nycsubway_df, vending == "NO")
```

3.  The proportion of stationentrances/exits without vending allows
    entrance is 0.3770492

\#\#Problem 3 \#First, clean the data in pols-month.csv. Use separate()
to break up the variable mon into integer variables year, month, and
day;

\#replace month number with month name; create a president variable
taking values gop and dem, and remove prez\_dem and prez\_gop; and
remove the day variable.

``` r
pols_months_df =
  read_csv(
  "./data/fivethirtyeight_datasets/pols-month.csv") 
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

``` r
pols_months_df = janitor::clean_names(pols_months_df)  

pols_months_df = drop_na(pols_months_df)  

pols_months_df = separate(pols_months_df, mon, into = c("year", "month", "day"), sep = "-" )   

pols_months_df =  mutate(pols_months_df, year = as.integer (year), 
         month=month.name[as.integer(month)],
         day = as.integer(day))
         
pols_months_df =  mutate(pols_months_df, president = case_when(
           prez_gop == 1 ~ "gop",
           prez_dem == 1 ~ "dem")
         ) 
  
pols_months_df = select(pols_months_df, -prez_dem,-prez_gop,-day)

view(pols_months_df)   

skimr::skim(pols_months_df)
```

|                                                  |                  |
| :----------------------------------------------- | :--------------- |
| Name                                             | pols\_months\_df |
| Number of rows                                   | 822              |
| Number of columns                                | 9                |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_   |                  |
| Column type frequency:                           |                  |
| character                                        | 2                |
| numeric                                          | 7                |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ |                  |
| Group variables                                  | None             |

Data summary

**Variable type: character**

| skim\_variable | n\_missing | complete\_rate | min | max | empty | n\_unique | whitespace |
| :------------- | ---------: | -------------: | --: | --: | ----: | --------: | ---------: |
| month          |          0 |           1.00 |   3 |   9 |     0 |        12 |          0 |
| president      |          5 |           0.99 |   3 |   3 |     0 |         2 |          0 |

**Variable type: numeric**

| skim\_variable | n\_missing | complete\_rate |    mean |    sd |   p0 |  p25 |  p50 |  p75 | p100 | hist  |
| :------------- | ---------: | -------------: | ------: | ----: | ---: | ---: | ---: | ---: | ---: | :---- |
| year           |          0 |              1 | 1980.75 | 19.79 | 1947 | 1964 | 1981 | 1998 | 2015 | ▇▇▇▇▇ |
| gov\_gop       |          0 |              1 |   22.48 |  5.68 |   12 |   18 |   22 |   28 |   34 | ▆▆▇▅▅ |
| sen\_gop       |          0 |              1 |   46.10 |  6.38 |   32 |   42 |   46 |   51 |   56 | ▃▃▇▇▇ |
| rep\_gop       |          0 |              1 |  194.92 | 29.24 |  141 |  176 |  195 |  222 |  253 | ▃▇▆▃▅ |
| gov\_dem       |          0 |              1 |   27.20 |  5.94 |   17 |   22 |   28 |   32 |   41 | ▆▅▇▆▂ |
| sen\_dem       |          0 |              1 |   54.41 |  7.37 |   44 |   48 |   53 |   58 |   71 | ▇▆▇▃▂ |
| rep\_dem       |          0 |              1 |  244.97 | 31.37 |  188 |  211 |  250 |  268 |  301 | ▇▂▇▇▅ |

\#Second, clean the data in snp.csv using a similar process to the
above. For consistency across datasets, arrange according to year and
month, and organize so that year and month are the leading columns.

``` r
snp_df =  read_csv(
  "./data/fivethirtyeight_datasets/snp.csv")
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

``` r
snp_df =  janitor::clean_names(snp_df) 
snp_df =    drop_na(snp_df) 
snp_df =    separate(snp_df, date, c("month","day","year")) 
 
snp_df =    mutate(snp_df, year = as.integer(year),
    month = month.name[as.integer(month)],
    day = as.integer(day))

    

snp_df =    relocate(snp_df, year, month)
snp_df =    arrange(snp_df, year, month) 
snp_df =    select(snp_df, -day)

view(snp_df)

skimr::skim(snp_df)
```

|                                                  |         |
| :----------------------------------------------- | :------ |
| Name                                             | snp\_df |
| Number of rows                                   | 787     |
| Number of columns                                | 3       |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_   |         |
| Column type frequency:                           |         |
| character                                        | 1       |
| numeric                                          | 2       |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ |         |
| Group variables                                  | None    |

Data summary

**Variable type: character**

| skim\_variable | n\_missing | complete\_rate | min | max | empty | n\_unique | whitespace |
| :------------- | ---------: | -------------: | --: | --: | ----: | --------: | ---------: |
| month          |          0 |              1 |   3 |   9 |     0 |        12 |          0 |

**Variable type: numeric**

| skim\_variable | n\_missing | complete\_rate |    mean |     sd |      p0 |     p25 |     p50 |    p75 |    p100 | hist  |
| :------------- | ---------: | -------------: | ------: | -----: | ------: | ------: | ------: | -----: | ------: | :---- |
| year           |          0 |              1 | 1982.29 |  18.95 | 1950.00 | 1966.00 | 1982.00 | 1999.0 | 2015.00 | ▇▇▇▇▇ |
| close          |          0 |              1 |  474.89 | 545.96 |   17.05 |   83.74 |  138.53 |  941.8 | 2107.39 | ▇▁▂▁▁ |

\#Third, tidy the unemployment data so that it can be merged with the
previous datasets. This process will involve switching from “wide” to
“long” format; ensuring that key variables have the same name; and
ensuring that key variables take the same values.

``` r
unemploy_df = read_csv(file = "./data/fivethirtyeight_datasets/unemployment.csv") 
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

``` r
unemploy_df = janitor::clean_names(unemploy_df) 
unemploy_df =  drop_na(unemploy_df)
view(unemploy_df)

unemploy_tidy_df = pivot_longer(unemploy_df,jan:dec,names_to = "month",values_to = "percentage")


view(unemploy_tidy_df)


month_df = 
  tibble(
    month = c("jan","feb","mar","apr","may","jun","jul","aug","sep","oct","nov","dec"),
    month_name = month.name
  )


unemploy_long_tidy_df = left_join(unemploy_tidy_df, month_df, by = "month")
unemploy_long_tidy_df =  select(unemploy_long_tidy_df, -month) 
unemploy_long_tidy_df =  select(unemploy_long_tidy_df, year, month=month_name, percentage)

unemploy_long_tidy_df =   relocate(unemploy_long_tidy_df, year, month)

view(unemploy_long_tidy_df)
```

\#Join the datasets by merging snp into pols, and merging unemployment
into the result.

``` r
pols_snp_df = 
  left_join(pols_months_df, snp_df, by = c("year"="year","month"="month"))

pols_snp_unemploy =
  left_join(pols_snp_df, unemploy_long_tidy_df, by = "year","month")
```

\#Write a short paragraph about these datasets. Explain briefly what
each dataset contained, and describe the resulting dataset (e.g. give
the dimension, range of years, and names of key variables).
