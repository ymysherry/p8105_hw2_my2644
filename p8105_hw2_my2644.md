P8105\_hw2\_my2644
================
ymysherry
9/29/2020

This is my solution to HW2.

``` r
library(tidyverse)
```

    ## ── Attaching packages ────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ───────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

\#\#Problem 1 \#Read the Mr. Trashwheel dataset.

``` r
trashwheel_df =
  read_xlsx(
  "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
  sheet = "Mr. Trash Wheel",
  range = cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read precipitation data for 2018 and 2017

``` r
precip_2018 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
  sheet = "2018 Precipitation",
  skip = 1, 
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2018)  %>%
  relocate(year)
```

``` r
precip_2017 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
  sheet = "2017 Precipitation",
  skip = 1, 
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2017)  %>%
  relocate(year)
```

Now combine annual precipitation.

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )


precip_df = 
bind_rows(precip_2018, precip_2017) 
left_join(precip_df, month_df, by = "month")
```

    ## # A tibble: 24 x 4
    ##     year month total month_name
    ##    <dbl> <dbl> <dbl> <chr>     
    ##  1  2018     1  0.94 January   
    ##  2  2018     2  4.8  February  
    ##  3  2018     3  2.69 March     
    ##  4  2018     4  4.69 April     
    ##  5  2018     5  9.27 May       
    ##  6  2018     6  4.77 June      
    ##  7  2018     7 10.2  July      
    ##  8  2018     8  6.45 August    
    ##  9  2018     9 10.5  September 
    ## 10  2018    10  2.12 October   
    ## # … with 14 more rows

``` r
 nrow(trashwheel_df)
```

    ## [1] 344

This dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trash collects that trash, and stores it in a dumpster. The dataset
contains information on year, months, and trash collected, including
some specific kinds of trash. There are a total of 344 rows in our final
dataset. Additional data sheets include month precipitation data.

Look for total precipitation in 2018 and median number of sports balls
in a dumpster in 2017

``` r
sum(pull(precip_2018,total),na.rm=TRUE)
```

    ## [1] 70.33

The total precipiration in 2018 is 70.33 inches.

``` r
sports_balls_2017_df= filter(trashwheel_df, year==2017)
median(pull(sports_balls_2017_df, sports_balls), na.rm= TRUE)
```

    ## [1] 8

The median number of sports balls in a dumpster in 2017 is 8.

\#\#Problem 2 \#Read and clean the NYC subway dataset. Retain useful
variables and convert the entry variable from character (YES vs NO) to a
logical variable

``` r
nycsubway_df =
  read_csv(
  "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv")
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

``` r
nycsubway_df = janitor::clean_names(nycsubway_df) 

nycsubway_df = 
  select(nycsubway_df, line, station_name, station_latitude, station_longitude, route1:route11, entrance_type, entry, vending, ada)

nycsubway_df =  
  mutate(nycsubway_df, entry = recode (entry, "YES"="TRUE","NO"="FALSE"), entry = as.logical(entry))
skimr::skim(nycsubway_df)
```

|                                                  |               |
| :----------------------------------------------- | :------------ |
| Name                                             | nycsubway\_df |
| Number of rows                                   | 1868          |
| Number of columns                                | 19            |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_   |               |
| Column type frequency:                           |               |
| character                                        | 11            |
| logical                                          | 2             |
| numeric                                          | 6             |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ |               |
| Group variables                                  | None          |

Data summary

**Variable type: character**

| skim\_variable | n\_missing | complete\_rate | min | max | empty | n\_unique | whitespace |
| :------------- | ---------: | -------------: | --: | --: | ----: | --------: | ---------: |
| line           |          0 |           1.00 |   5 |  17 |     0 |        36 |          0 |
| station\_name  |          0 |           1.00 |   4 |  39 |     0 |       356 |          0 |
| route1         |          0 |           1.00 |   1 |   2 |     0 |        24 |          0 |
| route2         |        848 |           0.55 |   1 |   2 |     0 |        20 |          0 |
| route3         |       1374 |           0.26 |   1 |   2 |     0 |        18 |          0 |
| route4         |       1547 |           0.17 |   1 |   1 |     0 |        13 |          0 |
| route5         |       1630 |           0.13 |   1 |   1 |     0 |        12 |          0 |
| route6         |       1741 |           0.07 |   1 |   1 |     0 |         7 |          0 |
| route7         |       1788 |           0.04 |   1 |   2 |     0 |         7 |          0 |
| entrance\_type |          0 |           1.00 |   4 |   9 |     0 |         7 |          0 |
| vending        |          0 |           1.00 |   2 |   3 |     0 |         2 |          0 |

**Variable type: logical**

| skim\_variable | n\_missing | complete\_rate | mean | count               |
| :------------- | ---------: | -------------: | ---: | :------------------ |
| entry          |          0 |              1 | 0.94 | TRU: 1753, FAL: 115 |
| ada            |          0 |              1 | 0.25 | FAL: 1400, TRU: 468 |

**Variable type: numeric**

| skim\_variable     | n\_missing | complete\_rate |    mean |   sd |      p0 |     p25 |     p50 |     p75 |    p100 | hist  |
| :----------------- | ---------: | -------------: | ------: | ---: | ------: | ------: | ------: | ------: | ------: | :---- |
| station\_latitude  |          0 |           1.00 |   40.73 | 0.07 |   40.58 |   40.69 |   40.73 |   40.77 |   40.90 | ▂▅▇▃▂ |
| station\_longitude |          0 |           1.00 | \-73.94 | 0.06 | \-74.03 | \-73.99 | \-73.96 | \-73.91 | \-73.76 | ▇▆▃▂▁ |
| route8             |       1820 |           0.03 |    2.98 | 1.94 |    1.00 |    1.00 |    4.00 |    5.00 |    5.00 | ▇▁▁▂▇ |
| route9             |       1840 |           0.01 |    2.54 | 1.17 |    2.00 |    2.00 |    2.00 |    2.00 |    5.00 | ▇▁▁▁▂ |
| route10            |       1845 |           0.01 |    3.00 | 0.00 |    3.00 |    3.00 |    3.00 |    3.00 |    3.00 | ▁▁▇▁▁ |
| route11            |       1845 |           0.01 |    7.00 | 0.00 |    7.00 |    7.00 |    7.00 |    7.00 |    7.00 | ▁▁▇▁▁ |

\#Describe the dataset

This dataset contains information from the NYC subway transit data. The
dataset contains 19 variables in total, including information on
entrance, exit, station names, routes, lines, as well as specific
longitude and latitude of subway stations. There are a total of 1868
rows in our final dataset. Additional data cleaning has been performed
by the janitor step. Entry variable has been converted from character to
logical by using mutate. This is a tidy dataset with dimensions of
35492. Number of columns represents variables and number of rows
represents observations.
