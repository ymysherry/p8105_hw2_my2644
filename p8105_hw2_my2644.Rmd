---
title: "P8105_hw2_my2644"
author: "ymysherry"
date: "9/29/2020"
output: github_document
---

This is my solution to HW2.

```{r setup}
library(tidyverse)
library(readxl)
```

##Problem 1
#Read the Mr. Trashwheel dataset.

```{r}
trashwheel_df =
  read_xlsx(
  "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
  sheet = "Mr. Trash Wheel",
  range = cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read precipitation data for 2018 and 2017
```{r}
precip_2018 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
  sheet = "2018 Precipitation",
  skip = 1, 
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2018)  %>%
  relocate(year)
```
```{r}
precip_2017 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
  sheet = "2017 Precipitation",
  skip = 1, 
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2017)  %>%
  relocate(year)
```

Now combine annual precipitation.

```{r}
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )


precip_df = 
bind_rows(precip_2018, precip_2017) 
left_join(precip_df, month_df, by = "month")
  
```

```{r}
 nrow(trashwheel_df)
```


This dataset contains information from the Mr. Trashwheel trash collector in Baltimore, Maryland. As trash enters the inner harbor, the trash collects that trash, and stores it in a dumpster. The dataset contains information on year, months, and trash collected, including some specific kinds of trash. There are a total of `r nrow(trashwheel_df)` rows in our final dataset. Additional data sheets include month precipitation data.

Look for total precipitation in 2018 and median number of sports balls in a dumpster in 2017
```{r}
sum(pull(precip_2018,total),na.rm=TRUE)
```
The total precipiration in 2018 is 70.33 inches.

```{r}
sports_balls_2017_df= filter(trashwheel_df, year==2017)
median(pull(sports_balls_2017_df, sports_balls), na.rm= TRUE)
```
The median number of sports balls in a dumpster in 2017 is 8.


##Problem 2
#Read and clean the NYC subway dataset. Retain useful variables and convert the entry variable from character (YES vs NO) to a logical variable

```{r}
nycsubway_df =
  read_csv(
  "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv")

nycsubway_df = janitor::clean_names(nycsubway_df) 

nycsubway_df = 
  select(nycsubway_df, line, station_name, station_latitude, station_longitude, route1:route11, entrance_type, entry, vending, ada)

nycsubway_df =  
  mutate(nycsubway_df, entry = recode (entry, "YES"="TRUE","NO"="FALSE"), entry = as.logical(entry))
skimr::skim(nycsubway_df)
```
#Describe the dataset

This dataset contains information from the NYC subway transit data. The dataset contains 19 variables in total, including information on entrance, exit, station names, routes, lines, as well as specific longitude and latitude of subway stations. There are a total of `r nrow(nycsubway_df)` rows in our final dataset. Additional data cleaning has been performed by the janitor step. Entry variable has been converted from character to logical by using mutate. This is a tidy dataset with dimensions of `r nrow(nycsubway_df)*ncol(nycsubway_df)`. Number of columns represents variables and number of rows represents observations.

##Answering questions using the NYC subway transit data
#how many distinct stations (by name and line) are there
```{r}
distinct_stations_df = 
  distinct(nycsubway_df, line, station_name, .keep_all = TRUE)
```
1. There are `r nrow(distinct_stations_df)` distinct stations

#how many stations are ADA compliant
```{r}
ADAcompliant_df=
  filter(distinct_stations_df, ada == TRUE)
```
2. `r nrow(ADAcompliant_df)` stations are ADA compliant

#What proportion of station entrances / exits without vending allow entrance
```{r}
entrance_novending_df = 
  filter(nycsubway_df, vending == "NO", entry == TRUE) 

novending_df = 
  filter(nycsubway_df, vending == "NO")
```
3. The proportion of stationentrances/exits without vending allows entrance is `r nrow(entrance_novending_df)/nrow(novending_df)`


##Problem 3
#First, clean the data in pols-month.csv. Use separate() to break up the variable mon into integer variables year, month, and day; 

#replace month number with month name; create a president variable taking values gop and dem, and remove prez_dem and prez_gop; and remove the day variable.
```{r}
pols_months_df =
  read_csv(
  "./data/fivethirtyeight_datasets/pols-month.csv") 

pols_months_df = janitor::clean_names(pols_months_df)  

pols_months_df = drop_na(pols_months_df)  

pols_months_df = separate(pols_months_df, mon, into = c("year", "month", "day"), sep = "-" )   

pols_months_df =  mutate(pols_months_df, year = as.integer (year), 
         month=month.name[as.integer(month)],
         day = as.integer(day))
         
pols_months_df =  mutate(pols_months_df, president = case_when(
           prez_gop == 1 ~ "gop",
           prez_dem == 1 ~ "dem")
         ) 
  
pols_months_df = select(pols_months_df, -prez_dem,-prez_gop,-day)

view(pols_months_df)   

skimr::skim(pols_months_df)
```



#Second, clean the data in snp.csv using a similar process to the above. For consistency across datasets, arrange according to year and month, and organize so that year and month are the leading columns.

```{r}
snp_df =  read_csv(
  "./data/fivethirtyeight_datasets/snp.csv")
snp_df =  janitor::clean_names(snp_df) 
snp_df =    drop_na(snp_df) 
snp_df =    separate(snp_df, date, c("month","day","year")) 
 
snp_df =    mutate(snp_df, year = as.integer(year),
    month = month.name[as.integer(month)],
    day = as.integer(day))

    

snp_df =    relocate(snp_df, year, month)
snp_df =    arrange(snp_df, year, month) 
snp_df =    select(snp_df, -day)

view(snp_df)

skimr::skim(snp_df)
```



#Third, tidy the unemployment data so that it can be merged with the previous datasets. This process will involve switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values.

```{r}
unemploy_df = read_csv(file = "./data/fivethirtyeight_datasets/unemployment.csv") 
unemploy_df = janitor::clean_names(unemploy_df) 
unemploy_df =  drop_na(unemploy_df)
view(unemploy_df)

unemploy_tidy_df = pivot_longer(unemploy_df,jan:dec,names_to = "month",values_to = "percentage")


view(unemploy_tidy_df)


month_df = 
  tibble(
    month = c("jan","feb","mar","apr","may","jun","jul","aug","sep","oct","nov","dec"),
    month_name = month.name
  )


unemploy_long_tidy_df = left_join(unemploy_tidy_df, month_df, by = "month")

unemploy_long_tidy_df =  select(unemploy_long_tidy_df, -month) 

unemploy_long_tidy_df =   relocate(unemploy_long_tidy_df, year, month_name)

unemploy_long_tidy_df =  select(unemploy_long_tidy_df, year, month=month_name, percentage)

view(unemploy_long_tidy_df)


```



#Join the datasets by merging snp into pols, and merging unemployment into the result.
```{r}
pols_snp_df = 
  left_join(pols_months_df, snp_df, by = c("year"="year","month"="month"))
view(pols_snp_df)

pols_snp_unemploy_df =
  left_join(pols_snp_df, unemploy_long_tidy_df, by = "year","month")

view(pols_snp_unemploy_df)
```



#Write a short paragraph about these datasets. Explain briefly what each dataset contained, and describe the resulting dataset (e.g. give the dimension, range of years, and names of key variables).
```{r}
skimr::skim(pols_months_df)
skimr::skim(snp_df)
skimr::skim(unemploy_long_tidy_df)
skimr::skim(pols_snp_unemploy_df)
```
The dataset pols_months_df contains `r nrow(pols_months_df)` observations of 9 variables,  including date,the number of governors, senators, house representatives and presidents in democratic and republican parties at a certain year and month,

The dataset snp_df contains 787 observations of 3 variables related to S&P stock market index, including year, month, and close point of the S&P Index at a given time). The range of years is `r min(pull(snp_df,year))` and `r max(pull(snp_df,year))`.

The dataset unemploy_long_tidy_df contains 804 observations of 3 variables, including year, month, and the percentage of unemployment at a certain time. The range of years is `r min(pull(unemploy_long_tidy_df,year))` and `r max(pull(unemploy_long_tidy_df,year))`.


The final merged dataset pols_snp_unemploy_df contains 822 observations of 11 variables related to date,the number of governors, senators, house representatives, presidents in democratic and republican parties at a certain time, the S&P stock index, and the unemployment rate at given time, indicated by year, month, president, close (closing point of the S&P stock index), etc. The range of years is `r min(pull(pols_snp_unemploy_df,year))` and `r max(pull(pols_snp_unemploy_df,year))`.Percentage of unemployment data in 1947 is not available.



